{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "collapsed": true,
        "id": "KooykeTPosEb",
        "outputId": "e2c42149-e559-425c-ee47-aa3411f8e148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n",
            "MNE version: 1.6.1\n",
            "Configuration:\n",
            "  - Number of subjects: 109\n",
            "  - Sampling rate: 160 Hz\n",
            "  - Segment duration: 2.0s (320 samples)\n",
            "  - Number of channels: 17\n",
            "  - Motor channels: ['Fc3', 'Fc1', 'Fcz', 'Fc2', 'Fc4', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'Cp3', 'Cp1', 'Cpz', 'Cp2', 'Cp4']\n",
            "  - Motor imagery runs: [4, 6, 8, 10, 12, 14]\n",
            "============================================================\n",
            "DOWNLOADING PHYSIONET EEG DATA\n",
            "============================================================\n",
            "This will download motor imagery runs for 109 subjects\n",
            "Runs to download per subject: [4, 6, 8, 10, 12, 14]\n",
            "------------------------------------------------------------\n",
            "Created directories: /content/physionet_eeg, /content/processed_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 109/109 [1:12:15<00:00, 39.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "Download complete: 109/109 subjects\n",
            "============================================================\n",
            "PROCESSING EEG DATA\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 109/109 [00:52<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 320 and the array at index 87 has size 256",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1849592509.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;31m# Process all subjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_all_subjects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;31m# ## 6. Data Verification and Statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1849592509.py\u001b[0m in \u001b[0;36mprocess_all_subjects\u001b[0;34m()\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;31m# Concatenate all data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 320 and the array at index 87 has size 256"
          ]
        }
      ],
      "source": [
        "# Dataset: PhysioNet EEG Motor Movement/Imagery Dataset\n",
        "# Goal: Load, filter, segment EEG data for 109 subjects\n",
        "# =============================================================================\n",
        "\n",
        "!pip install mne==1.6.1 -q\n",
        "!pip install pyedflib -q\n",
        "!pip install wget -q\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "import wget\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "mne.set_log_level('WARNING')\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"MNE version: {mne.__version__}\")\n",
        "\n",
        "# ## 2. Configuration Parameters\n",
        "\n",
        "\n",
        "class Config:\n",
        "    # Dataset parameters\n",
        "    N_SUBJECTS = 109                    # Total subjects in dataset\n",
        "    SAMPLING_RATE = 160                 # Hz (PhysioNet EEG sampling rate)\n",
        "\n",
        "    # Preprocessing parameters\n",
        "    LOWCUT = 0.5                        # High-pass filter cutoff (Hz)\n",
        "    HIGHCUT = 45.0                      # Low-pass filter cutoff (Hz)\n",
        "\n",
        "    # Segmentation parameters\n",
        "    SEGMENT_DURATION = 2.0              # seconds\n",
        "    SEGMENT_SAMPLES = int(SEGMENT_DURATION * SAMPLING_RATE)  # 320 samples\n",
        "    OVERLAP = 0.5                       # 50% overlap between segments\n",
        "\n",
        "    # Motor cortex channels (10-10 system)\n",
        "    # These channels cover the sensorimotor cortex region\n",
        "    MOTOR_CHANNELS = [\n",
        "        'Fc3', 'Fc1', 'Fcz', 'Fc2', 'Fc4',  # Frontal-Central\n",
        "        'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',  # Central (Primary Motor)\n",
        "        'Cp3', 'Cp1', 'Cpz', 'Cp2', 'Cp4'   # Central-Parietal\n",
        "    ]\n",
        "    N_CHANNELS = len(MOTOR_CHANNELS)    # 17 channels\n",
        "\n",
        "    # Motor Imagery runs only (as specified)\n",
        "    # Runs 4, 8, 12: imagine opening/closing left or right fist\n",
        "    # Runs 6, 10, 14: imagine opening/closing both fists or both feet\n",
        "    MOTOR_IMAGERY_RUNS = [4, 6, 8, 10, 12, 14]\n",
        "\n",
        "    # Data split\n",
        "    TEST_SIZE = 0.2\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "    # Paths\n",
        "    DATA_DIR = '/content/physionet_eeg'\n",
        "    PROCESSED_DIR = '/content/processed_data'\n",
        "\n",
        "    # PhysioNet base URL\n",
        "    PHYSIONET_URL = 'https://physionet.org/files/eegmmidb/1.0.0'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  - Number of subjects: {config.N_SUBJECTS}\")\n",
        "print(f\"  - Sampling rate: {config.SAMPLING_RATE} Hz\")\n",
        "print(f\"  - Segment duration: {config.SEGMENT_DURATION}s ({config.SEGMENT_SAMPLES} samples)\")\n",
        "print(f\"  - Number of channels: {config.N_CHANNELS}\")\n",
        "print(f\"  - Motor channels: {config.MOTOR_CHANNELS}\")\n",
        "print(f\"  - Motor imagery runs: {config.MOTOR_IMAGERY_RUNS}\")\n",
        "\n",
        "# ## 3. Download Dataset from PhysioNet\n",
        "\n",
        "def create_directories():\n",
        "    \"\"\"Create necessary directories\"\"\"\n",
        "    os.makedirs(config.DATA_DIR, exist_ok=True)\n",
        "    os.makedirs(config.PROCESSED_DIR, exist_ok=True)\n",
        "    print(f\"Created directories: {config.DATA_DIR}, {config.PROCESSED_DIR}\")\n",
        "\n",
        "def download_subject_data(subject_id):\n",
        "    \"\"\"\n",
        "    Download EEG data for a single subject from PhysioNet\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    subject_id : int\n",
        "        Subject number (1-109)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    bool : True if successful, False otherwise\n",
        "    \"\"\"\n",
        "    subject_dir = os.path.join(config.DATA_DIR, f'S{subject_id:03d}')\n",
        "    os.makedirs(subject_dir, exist_ok=True)\n",
        "\n",
        "    files_downloaded = 0\n",
        "\n",
        "    for run in config.MOTOR_IMAGERY_RUNS:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        filepath = os.path.join(subject_dir, filename)\n",
        "\n",
        "        # Skip if file already exists\n",
        "        if os.path.exists(filepath):\n",
        "            files_downloaded += 1\n",
        "            continue\n",
        "\n",
        "        url = f'{config.PHYSIONET_URL}/S{subject_id:03d}/{filename}'\n",
        "\n",
        "        try:\n",
        "            wget.download(url, filepath, bar=None)\n",
        "            files_downloaded += 1\n",
        "        except Exception as e:\n",
        "            print(f\"\\n  Warning: Could not download {filename}: {e}\")\n",
        "\n",
        "    return files_downloaded == len(config.MOTOR_IMAGERY_RUNS)\n",
        "\n",
        "def download_all_data():\n",
        "    \"\"\"Download data for all subjects\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DOWNLOADING PHYSIONET EEG DATA\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"This will download motor imagery runs for {config.N_SUBJECTS} subjects\")\n",
        "    print(f\"Runs to download per subject: {config.MOTOR_IMAGERY_RUNS}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    create_directories()\n",
        "\n",
        "    successful = 0\n",
        "    failed_subjects = []\n",
        "\n",
        "    for subject_id in tqdm(range(1, config.N_SUBJECTS + 1), desc=\"Downloading\"):\n",
        "        if download_subject_data(subject_id):\n",
        "            successful += 1\n",
        "        else:\n",
        "            failed_subjects.append(subject_id)\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Download complete: {successful}/{config.N_SUBJECTS} subjects\")\n",
        "\n",
        "    if failed_subjects:\n",
        "        print(f\"Failed subjects: {failed_subjects}\")\n",
        "\n",
        "    return successful, failed_subjects\n",
        "\n",
        "successful, failed = download_all_data()\n",
        "\n",
        "# ## 4. EEG Loading and Preprocessing Functions\n",
        "\n",
        "def load_edf_file(filepath):\n",
        "    \"\"\"\n",
        "    Load an EDF file using MNE\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    filepath : str\n",
        "        Path to the EDF file\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    raw : mne.io.Raw\n",
        "        Raw EEG data object\n",
        "    \"\"\"\n",
        "    try:\n",
        "        raw = mne.io.read_raw_edf(filepath, preload=True, verbose=False)\n",
        "        return raw\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def select_motor_channels(raw):\n",
        "    \"\"\"\n",
        "    Select motor cortex channels from raw data\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    raw : mne.io.Raw\n",
        "        Raw EEG data\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    raw : mne.io.Raw\n",
        "        Raw data with only motor channels\n",
        "    \"\"\"\n",
        "    # Get available channels (handle different naming conventions)\n",
        "    available_channels = raw.ch_names\n",
        "\n",
        "    # PhysioNet uses format like 'Fc3.', 'C3.', etc. (with dots)\n",
        "    # We need to match our channel names\n",
        "    selected_channels = []\n",
        "\n",
        "    for ch in config.MOTOR_CHANNELS:\n",
        "        # Try different naming conventions\n",
        "        possible_names = [ch, ch + '.', ch.upper(), ch.upper() + '.',\n",
        "                         ch.lower(), ch.lower() + '.']\n",
        "\n",
        "        for name in possible_names:\n",
        "            if name in available_channels:\n",
        "                selected_channels.append(name)\n",
        "                break\n",
        "\n",
        "    if len(selected_channels) == 0:\n",
        "        print(f\"Warning: No motor channels found. Available: {available_channels[:10]}...\")\n",
        "        return None\n",
        "\n",
        "    # Pick only selected channels\n",
        "    raw.pick_channels(selected_channels)\n",
        "\n",
        "    return raw\n",
        "\n",
        "def apply_bandpass_filter(raw, lowcut=None, highcut=None):\n",
        "    \"\"\"\n",
        "    Apply band-pass filter to remove noise\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    raw : mne.io.Raw\n",
        "        Raw EEG data\n",
        "    lowcut : float\n",
        "        Low cutoff frequency (Hz)\n",
        "    highcut : float\n",
        "        High cutoff frequency (Hz)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    raw : mne.io.Raw\n",
        "        Filtered data\n",
        "    \"\"\"\n",
        "    if lowcut is None:\n",
        "        lowcut = config.LOWCUT\n",
        "    if highcut is None:\n",
        "        highcut = config.HIGHCUT\n",
        "\n",
        "    raw.filter(lowcut, highcut, fir_design='firwin', verbose=False)\n",
        "\n",
        "    return raw\n",
        "\n",
        "def segment_data(raw, segment_duration=None, overlap=None):\n",
        "    \"\"\"\n",
        "    Segment continuous EEG data into fixed-length epochs\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    raw : mne.io.Raw\n",
        "        Raw EEG data\n",
        "    segment_duration : float\n",
        "        Duration of each segment in seconds\n",
        "    overlap : float\n",
        "        Overlap ratio between segments (0-1)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    segments : np.ndarray\n",
        "        Shape: (n_segments, n_channels, n_samples)\n",
        "    \"\"\"\n",
        "    if segment_duration is None:\n",
        "        segment_duration = config.SEGMENT_DURATION\n",
        "    if overlap is None:\n",
        "        overlap = config.OVERLAP\n",
        "\n",
        "    # Get data array\n",
        "    data = raw.get_data()  # Shape: (n_channels, n_total_samples)\n",
        "    sfreq = raw.info['sfreq']\n",
        "\n",
        "    # Calculate segment parameters\n",
        "    segment_samples = int(segment_duration * sfreq)\n",
        "    step_samples = int(segment_samples * (1 - overlap))\n",
        "\n",
        "    # Extract segments\n",
        "    segments = []\n",
        "    n_samples = data.shape[1]\n",
        "\n",
        "    start = 0\n",
        "    while start + segment_samples <= n_samples:\n",
        "        segment = data[:, start:start + segment_samples]\n",
        "        segments.append(segment)\n",
        "        start += step_samples\n",
        "\n",
        "    if len(segments) == 0:\n",
        "        return None\n",
        "\n",
        "    return np.array(segments)\n",
        "\n",
        "def normalize_segments(segments):\n",
        "    \"\"\"\n",
        "    Z-score normalize each segment independently\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    segments : np.ndarray\n",
        "        Shape: (n_segments, n_channels, n_samples)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    normalized : np.ndarray\n",
        "        Normalized segments\n",
        "    \"\"\"\n",
        "    # Normalize each segment independently (across all channels and time)\n",
        "    normalized = np.zeros_like(segments)\n",
        "\n",
        "    for i in range(len(segments)):\n",
        "        segment = segments[i]\n",
        "        mean = np.mean(segment)\n",
        "        std = np.std(segment)\n",
        "        if std > 0:\n",
        "            normalized[i] = (segment - mean) / std\n",
        "        else:\n",
        "            normalized[i] = segment - mean\n",
        "\n",
        "    return normalized\n",
        "\n",
        "# ## 5. Process All Subjects\n",
        "\n",
        "def process_subject(subject_id, verbose=False):\n",
        "    \"\"\"\n",
        "    Process all motor imagery runs for a single subject\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    subject_id : int\n",
        "        Subject number (1-109)\n",
        "    verbose : bool\n",
        "        Print detailed information\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    segments : np.ndarray or None\n",
        "        All segments for this subject\n",
        "        Shape: (n_segments, n_channels, n_samples)\n",
        "    \"\"\"\n",
        "    subject_dir = os.path.join(config.DATA_DIR, f'S{subject_id:03d}')\n",
        "    all_segments = []\n",
        "\n",
        "    for run in config.MOTOR_IMAGERY_RUNS:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        filepath = os.path.join(subject_dir, filename)\n",
        "\n",
        "        if not os.path.exists(filepath):\n",
        "            if verbose:\n",
        "                print(f\"  File not found: {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Load EDF file\n",
        "        raw = load_edf_file(filepath)\n",
        "        if raw is None:\n",
        "            continue\n",
        "\n",
        "        # Select motor channels\n",
        "        raw = select_motor_channels(raw)\n",
        "        if raw is None:\n",
        "            continue\n",
        "\n",
        "        # Apply band-pass filter\n",
        "        raw = apply_bandpass_filter(raw)\n",
        "\n",
        "        # Segment data\n",
        "        segments = segment_data(raw)\n",
        "        if segments is None:\n",
        "            continue\n",
        "\n",
        "        all_segments.append(segments)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  Run {run}: {segments.shape[0]} segments\")\n",
        "\n",
        "    if len(all_segments) == 0:\n",
        "        return None\n",
        "\n",
        "    # Concatenate all segments\n",
        "    all_segments = np.concatenate(all_segments, axis=0)\n",
        "\n",
        "    # Normalize\n",
        "    all_segments = normalize_segments(all_segments)\n",
        "\n",
        "    return all_segments\n",
        "\n",
        "def process_all_subjects():\n",
        "    \"\"\"\n",
        "    Process EEG data for all subjects\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    X : np.ndarray\n",
        "        All EEG segments, shape: (n_total_segments, n_channels, n_samples)\n",
        "    y : np.ndarray\n",
        "        Subject labels (0 to 108), shape: (n_total_segments,)\n",
        "    subject_segment_counts : dict\n",
        "        Number of segments per subject\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PROCESSING EEG DATA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    all_X = []\n",
        "    all_y = []\n",
        "    subject_segment_counts = {}\n",
        "    skipped_subjects = []\n",
        "\n",
        "    for subject_id in tqdm(range(1, config.N_SUBJECTS + 1), desc=\"Processing\"):\n",
        "        segments = process_subject(subject_id)\n",
        "\n",
        "        if segments is None or len(segments) == 0:\n",
        "            skipped_subjects.append(subject_id)\n",
        "            continue\n",
        "\n",
        "        # Store segments and labels\n",
        "        n_segments = len(segments)\n",
        "        all_X.append(segments)\n",
        "        all_y.extend([subject_id - 1] * n_segments)  # Labels: 0 to 108\n",
        "\n",
        "        subject_segment_counts[subject_id] = n_segments\n",
        "\n",
        "    # Concatenate all data\n",
        "    X = np.concatenate(all_X, axis=0)\n",
        "    y = np.array(all_y)\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Processing complete!\")\n",
        "    print(f\"  - Total segments: {len(X)}\")\n",
        "    print(f\"  - Data shape: {X.shape}\")\n",
        "    print(f\"  - Subjects processed: {len(subject_segment_counts)}\")\n",
        "\n",
        "    if skipped_subjects:\n",
        "        print(f\"  - Skipped subjects: {skipped_subjects}\")\n",
        "\n",
        "    # Statistics\n",
        "    segments_per_subject = list(subject_segment_counts.values())\n",
        "    print(f\"  - Segments per subject: min={min(segments_per_subject)}, \"\n",
        "          f\"max={max(segments_per_subject)}, mean={np.mean(segments_per_subject):.1f}\")\n",
        "\n",
        "    return X, y, subject_segment_counts\n",
        "\n",
        "# Process all subjects\n",
        "X, y, segment_counts = process_all_subjects()\n",
        "\n",
        "# ## 6. Data Verification and Statistics\n",
        "\n",
        "def verify_data(X, y):\n",
        "    \"\"\"Verify processed data integrity\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATA VERIFICATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(f\"\\nData Shapes:\")\n",
        "    print(f\"  X (EEG data): {X.shape}\")\n",
        "    print(f\"    - Total segments: {X.shape[0]}\")\n",
        "    print(f\"    - Channels: {X.shape[1]}\")\n",
        "    print(f\"    - Samples per segment: {X.shape[2]}\")\n",
        "    print(f\"  y (labels): {y.shape}\")\n",
        "\n",
        "    print(f\"\\nLabel Statistics:\")\n",
        "    unique_labels = np.unique(y)\n",
        "    print(f\"  - Unique subjects: {len(unique_labels)}\")\n",
        "    print(f\"  - Label range: {unique_labels.min()} to {unique_labels.max()}\")\n",
        "\n",
        "    print(f\"\\nData Statistics:\")\n",
        "    print(f\"  - Mean: {np.mean(X):.6f}\")\n",
        "    print(f\"  - Std: {np.std(X):.6f}\")\n",
        "    print(f\"  - Min: {np.min(X):.6f}\")\n",
        "    print(f\"  - Max: {np.max(X):.6f}\")\n",
        "\n",
        "    # Check for NaN or Inf\n",
        "    nan_count = np.sum(np.isnan(X))\n",
        "    inf_count = np.sum(np.isinf(X))\n",
        "    print(f\"\\nData Quality:\")\n",
        "    print(f\"  - NaN values: {nan_count}\")\n",
        "    print(f\"  - Inf values: {inf_count}\")\n",
        "\n",
        "    # Class distribution\n",
        "    print(f\"\\nClass Distribution (samples per subject):\")\n",
        "    label_counts = np.bincount(y)\n",
        "    print(f\"  - Min: {label_counts.min()}\")\n",
        "    print(f\"  - Max: {label_counts.max()}\")\n",
        "    print(f\"  - Mean: {label_counts.mean():.1f}\")\n",
        "    print(f\"  - Std: {label_counts.std():.1f}\")\n",
        "\n",
        "    return True\n",
        "\n",
        "verify_data(X, y)\n",
        "\n",
        "# ## 7. Train/Test Split\n",
        "\n",
        "def create_train_test_split(X, y, test_size=None, random_state=None):\n",
        "    \"\"\"\n",
        "    Create stratified train/test split\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : np.ndarray\n",
        "        EEG segments\n",
        "    y : np.ndarray\n",
        "        Subject labels\n",
        "    test_size : float\n",
        "        Proportion of data for testing\n",
        "    random_state : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    X_train, X_test, y_train, y_test : np.ndarray\n",
        "        Split data\n",
        "    \"\"\"\n",
        "    if test_size is None:\n",
        "        test_size = config.TEST_SIZE\n",
        "    if random_state is None:\n",
        "        random_state = config.RANDOM_STATE\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=y  # Ensure balanced classes in both sets\n",
        "    )\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TRAIN/TEST SPLIT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Training set: {X_train.shape[0]} samples ({100*(1-test_size):.0f}%)\")\n",
        "    print(f\"Test set: {X_test.shape[0]} samples ({100*test_size:.0f}%)\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Create split\n",
        "X_train, X_test, y_train, y_test = create_train_test_split(X, y)\n",
        "\n",
        "# ## 8. Save Processed Data\n",
        "\n",
        "def save_processed_data(X_train, X_test, y_train, y_test, segment_counts):\n",
        "    \"\"\"Save all processed data to disk\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SAVING PROCESSED DATA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    os.makedirs(config.PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "    # Save as numpy arrays\n",
        "    np.save(os.path.join(config.PROCESSED_DIR, 'X_train.npy'), X_train)\n",
        "    np.save(os.path.join(config.PROCESSED_DIR, 'X_test.npy'), X_test)\n",
        "    np.save(os.path.join(config.PROCESSED_DIR, 'y_train.npy'), y_train)\n",
        "    np.save(os.path.join(config.PROCESSED_DIR, 'y_test.npy'), y_test)\n",
        "\n",
        "    # Save configuration and metadata\n",
        "    metadata = {\n",
        "        'n_subjects': config.N_SUBJECTS,\n",
        "        'n_channels': X_train.shape[1],\n",
        "        'n_samples': X_train.shape[2],\n",
        "        'sampling_rate': config.SAMPLING_RATE,\n",
        "        'segment_duration': config.SEGMENT_DURATION,\n",
        "        'motor_channels': config.MOTOR_CHANNELS,\n",
        "        'lowcut': config.LOWCUT,\n",
        "        'highcut': config.HIGHCUT,\n",
        "        'segment_counts': segment_counts,\n",
        "        'train_size': len(X_train),\n",
        "        'test_size': len(X_test)\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(config.PROCESSED_DIR, 'metadata.pkl'), 'wb') as f:\n",
        "        pickle.dump(metadata, f)\n",
        "\n",
        "    # Print saved file sizes\n",
        "    print(f\"\\nSaved files in {config.PROCESSED_DIR}:\")\n",
        "    for filename in os.listdir(config.PROCESSED_DIR):\n",
        "        filepath = os.path.join(config.PROCESSED_DIR, filename)\n",
        "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
        "        print(f\"  - {filename}: {size_mb:.2f} MB\")\n",
        "\n",
        "    print(\"\\nData saved successfully!\")\n",
        "\n",
        "    return metadata\n",
        "\n",
        "metadata = save_processed_data(X_train, X_test, y_train, y_test, segment_counts)\n",
        "\n",
        "# ## 9. (Optional) Mount Google Drive for Persistent Storage\n",
        "\n",
        "# Uncomment and run this cell to save data to Google Drive\n",
        "# This allows you to access the processed data in future sessions\n",
        "\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy processed data to Google Drive\n",
        "import shutil\n",
        "drive_path = '/content/drive/MyDrive/EEG_Person_ID'\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(config.PROCESSED_DIR):\n",
        "    src = os.path.join(config.PROCESSED_DIR, filename)\n",
        "    dst = os.path.join(drive_path, filename)\n",
        "    shutil.copy(src, dst)\n",
        "    print(f\"Copied {filename} to Google Drive\")\n",
        "\n",
        "print(f\"\\nAll data saved to: {drive_path}\")\n",
        "\"\"\"\n",
        "\n",
        "# ## 10. Summary and Next Steps\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PREPROCESSING COMPLETE - SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\"\"\n",
        "Dataset: PhysioNet EEG Motor Movement/Imagery\n",
        "\n",
        "Preprocessing Steps:\n",
        "1. ✓ Downloaded motor imagery runs for {config.N_SUBJECTS} subjects\n",
        "2. ✓ Selected {config.N_CHANNELS} motor cortex channels\n",
        "3. ✓ Applied band-pass filter ({config.LOWCUT}-{config.HIGHCUT} Hz)\n",
        "4. ✓ Segmented into {config.SEGMENT_DURATION}s epochs ({config.SEGMENT_SAMPLES} samples)\n",
        "5. ✓ Normalized segments (z-score)\n",
        "6. ✓ Created train/test split (80/20)\n",
        "7. ✓ Saved processed data\n",
        "\n",
        "Final Data:\n",
        "- Training samples: {len(X_train)}\n",
        "- Test samples: {len(X_test)}\n",
        "- Shape: (samples, {X_train.shape[1]} channels, {X_train.shape[2]} time points)\n",
        "- Number of classes: {len(np.unique(y_train))} subjects\n",
        "\n",
        "Files saved in: {config.PROCESSED_DIR}\n",
        "- X_train.npy, X_test.npy (EEG data)\n",
        "- y_train.npy, y_test.npy (labels)\n",
        "- metadata.pkl (configuration)\n",
        "\n",
        "Next Step: Run Notebook 2 (CNN + GRU Model) to train the classifier\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture: 1D CNN → GRU → Dense Classification\n",
        "# Task: Classify which subject (1-109) a given EEG segment belongs to\n",
        "# =============================================================================\n",
        "\n",
        "# ## 1. Setup and Imports\n",
        "\n",
        "!pip install torch torchvision -q\n",
        "!pip install scikit-learn -q\n",
        "!pip install seaborn -q\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# ## 2. Configuration\n",
        "\n",
        "class ModelConfig:\n",
        "    # Data paths\n",
        "    PROCESSED_DIR = '/content/processed_data'\n",
        "    MODEL_DIR = '/content/models'\n",
        "\n",
        "    # Model architecture\n",
        "    N_CHANNELS = 17          # Number of EEG channels (from preprocessing)\n",
        "    N_SAMPLES = 320          # Samples per segment (2s * 160Hz)\n",
        "    N_CLASSES = 109          # Number of subjects\n",
        "\n",
        "    # CNN parameters\n",
        "    CNN_FILTERS = [32, 64, 128]  # Filters for each conv layer\n",
        "    CNN_KERNEL_SIZE = 7          # Kernel size for 1D convolution\n",
        "    CNN_POOL_SIZE = 2            # Max pooling size\n",
        "    DROPOUT_CNN = 0.3            # Dropout after CNN\n",
        "\n",
        "    # GRU parameters\n",
        "    GRU_HIDDEN_SIZE = 128        # Hidden size of GRU\n",
        "    GRU_NUM_LAYERS = 2           # Number of GRU layers\n",
        "    GRU_BIDIRECTIONAL = True     # Use bidirectional GRU\n",
        "    DROPOUT_GRU = 0.3            # Dropout in GRU\n",
        "\n",
        "    # Dense layer parameters\n",
        "    DENSE_HIDDEN = 256           # Hidden units before output\n",
        "    DROPOUT_DENSE = 0.5          # Dropout before output\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 64\n",
        "    LEARNING_RATE = 0.001\n",
        "    WEIGHT_DECAY = 1e-4           # L2 regularization\n",
        "    N_EPOCHS = 50\n",
        "    EARLY_STOPPING_PATIENCE = 10\n",
        "    LR_SCHEDULER_PATIENCE = 5\n",
        "\n",
        "    # Random seed\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "config = ModelConfig()\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(config.RANDOM_STATE)\n",
        "np.random.seed(config.RANDOM_STATE)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(config.RANDOM_STATE)\n",
        "\n",
        "print(\"Model Configuration:\")\n",
        "print(f\"  - Input shape: ({config.N_CHANNELS}, {config.N_SAMPLES})\")\n",
        "print(f\"  - CNN filters: {config.CNN_FILTERS}\")\n",
        "print(f\"  - GRU hidden: {config.GRU_HIDDEN_SIZE}, layers: {config.GRU_NUM_LAYERS}\")\n",
        "print(f\"  - Bidirectional: {config.GRU_BIDIRECTIONAL}\")\n",
        "print(f\"  - Output classes: {config.N_CLASSES}\")\n",
        "\n",
        "# ## 3. Load Preprocessed Data\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load preprocessed data from disk\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"LOADING PREPROCESSED DATA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    X_train = np.load(os.path.join(config.PROCESSED_DIR, 'X_train.npy'))\n",
        "    X_test = np.load(os.path.join(config.PROCESSED_DIR, 'X_test.npy'))\n",
        "    y_train = np.load(os.path.join(config.PROCESSED_DIR, 'y_train.npy'))\n",
        "    y_test = np.load(os.path.join(config.PROCESSED_DIR, 'y_test.npy'))\n",
        "\n",
        "    # Load metadata\n",
        "    with open(os.path.join(config.PROCESSED_DIR, 'metadata.pkl'), 'rb') as f:\n",
        "        metadata = pickle.load(f)\n",
        "\n",
        "    print(f\"Training data: {X_train.shape}\")\n",
        "    print(f\"Test data: {X_test.shape}\")\n",
        "    print(f\"Training labels: {y_train.shape}\")\n",
        "    print(f\"Test labels: {y_test.shape}\")\n",
        "    print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
        "\n",
        "    # Update config with actual data dimensions\n",
        "    config.N_CHANNELS = X_train.shape[1]\n",
        "    config.N_SAMPLES = X_train.shape[2]\n",
        "    config.N_CLASSES = len(np.unique(y_train))\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, metadata\n",
        "\n",
        "X_train, X_test, y_train, y_test, metadata = load_data()\n",
        "\n",
        "# ## 4. Create PyTorch Datasets and DataLoaders\n",
        "\n",
        "class EEGDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for EEG data\"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : np.ndarray\n",
        "            EEG data of shape (n_samples, n_channels, n_timepoints)\n",
        "        y : np.ndarray\n",
        "            Labels of shape (n_samples,)\n",
        "        \"\"\"\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "def create_dataloaders(X_train, X_test, y_train, y_test, batch_size=None):\n",
        "    \"\"\"Create PyTorch DataLoaders\"\"\"\n",
        "    if batch_size is None:\n",
        "        batch_size = config.BATCH_SIZE\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = EEGDataset(X_train, y_train)\n",
        "    test_dataset = EEGDataset(X_test, y_test)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "\n",
        "    print(f\"\\nDataLoaders created:\")\n",
        "    print(f\"  - Training batches: {len(train_loader)}\")\n",
        "    print(f\"  - Test batches: {len(test_loader)}\")\n",
        "    print(f\"  - Batch size: {batch_size}\")\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = create_dataloaders(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# ## 5. Define CNN + GRU Model Architecture\n",
        "\n",
        "class CNN_GRU_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN + GRU Hybrid Model for EEG Person Identification\n",
        "\n",
        "    Architecture:\n",
        "    1. 1D CNN layers: Extract spatial-frequency features from raw EEG\n",
        "    2. GRU layers: Capture temporal dynamics\n",
        "    3. Dense layers: Classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_channels, n_samples, n_classes, config):\n",
        "        super(CNN_GRU_Model, self).__init__()\n",
        "\n",
        "        self.n_channels = n_channels\n",
        "        self.n_samples = n_samples\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # =====================================================================\n",
        "        # CNN LAYERS (1D Convolution along time axis)\n",
        "        # Input: (batch, channels, time_samples)\n",
        "        # =====================================================================\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            # Conv Block 1\n",
        "            nn.Conv1d(n_channels, config.CNN_FILTERS[0],\n",
        "                     kernel_size=config.CNN_KERNEL_SIZE, padding='same'),\n",
        "            nn.BatchNorm1d(config.CNN_FILTERS[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(config.CNN_POOL_SIZE),\n",
        "\n",
        "            # Conv Block 2\n",
        "            nn.Conv1d(config.CNN_FILTERS[0], config.CNN_FILTERS[1],\n",
        "                     kernel_size=config.CNN_KERNEL_SIZE, padding='same'),\n",
        "            nn.BatchNorm1d(config.CNN_FILTERS[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(config.CNN_POOL_SIZE),\n",
        "\n",
        "            # Conv Block 3\n",
        "            nn.Conv1d(config.CNN_FILTERS[1], config.CNN_FILTERS[2],\n",
        "                     kernel_size=config.CNN_KERNEL_SIZE, padding='same'),\n",
        "            nn.BatchNorm1d(config.CNN_FILTERS[2]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(config.CNN_POOL_SIZE),\n",
        "\n",
        "            nn.Dropout(config.DROPOUT_CNN)\n",
        "        )\n",
        "\n",
        "        # Calculate CNN output size\n",
        "        # After 3 pooling layers of size 2: n_samples / 8\n",
        "        cnn_output_time = n_samples // 8  # 320 / 8 = 40\n",
        "\n",
        "        # =====================================================================\n",
        "        # GRU LAYERS\n",
        "        # Input: (batch, seq_len, features) - we transpose CNN output\n",
        "        # =====================================================================\n",
        "\n",
        "        gru_input_size = config.CNN_FILTERS[2]  # 128 features from CNN\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=gru_input_size,\n",
        "            hidden_size=config.GRU_HIDDEN_SIZE,\n",
        "            num_layers=config.GRU_NUM_LAYERS,\n",
        "            batch_first=True,\n",
        "            bidirectional=config.GRU_BIDIRECTIONAL,\n",
        "            dropout=config.DROPOUT_GRU if config.GRU_NUM_LAYERS > 1 else 0\n",
        "        )\n",
        "\n",
        "        # GRU output size\n",
        "        gru_output_size = config.GRU_HIDDEN_SIZE * (2 if config.GRU_BIDIRECTIONAL else 1)\n",
        "\n",
        "        # =====================================================================\n",
        "        # DENSE LAYERS (Classification Head)\n",
        "        # =====================================================================\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(gru_output_size, config.DENSE_HIDDEN),\n",
        "            nn.BatchNorm1d(config.DENSE_HIDDEN),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.DROPOUT_DENSE),\n",
        "            nn.Linear(config.DENSE_HIDDEN, n_classes)\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize model weights\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        x : torch.Tensor\n",
        "            Input tensor of shape (batch, n_channels, n_samples)\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        output : torch.Tensor\n",
        "            Class logits of shape (batch, n_classes)\n",
        "        \"\"\"\n",
        "        # CNN: (batch, channels, time) -> (batch, cnn_filters, reduced_time)\n",
        "        cnn_out = self.cnn_layers(x)\n",
        "\n",
        "        # Transpose for GRU: (batch, cnn_filters, time) -> (batch, time, cnn_filters)\n",
        "        gru_in = cnn_out.transpose(1, 2)\n",
        "\n",
        "        # GRU: (batch, time, features) -> (batch, time, hidden*directions)\n",
        "        gru_out, hidden = self.gru(gru_in)\n",
        "\n",
        "        # Take the last output (or concatenate last hidden states for bidirectional)\n",
        "        # Using the final hidden state from both directions\n",
        "        if self.gru.bidirectional:\n",
        "            # Concatenate the final hidden states from both directions\n",
        "            final_hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            final_hidden = hidden[-1]\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(final_hidden)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Create model instance\n",
        "model = CNN_GRU_Model(\n",
        "    n_channels=config.N_CHANNELS,\n",
        "    n_samples=config.N_SAMPLES,\n",
        "    n_classes=config.N_CLASSES,\n",
        "    config=config\n",
        ").to(device)\n",
        "\n",
        "# Print model summary\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL ARCHITECTURE\")\n",
        "print(\"=\" * 60)\n",
        "print(model)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Test forward pass\n",
        "test_input = torch.randn(2, config.N_CHANNELS, config.N_SAMPLES).to(device)\n",
        "test_output = model(test_input)\n",
        "print(f\"\\nTest forward pass:\")\n",
        "print(f\"  Input shape: {test_input.shape}\")\n",
        "print(f\"  Output shape: {test_output.shape}\")\n",
        "\n",
        "# ## 6. Training Functions\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "\n",
        "    def __init__(self, patience=10, min_delta=0, restore_best_weights=True):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.best_weights = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_weights = model.state_dict().copy()\n",
        "        elif val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.restore_best_weights:\n",
        "                    model.load_state_dict(self.best_weights)\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Store predictions\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluate model on a dataset\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
        "\n",
        "# ## 7. Training Loop\n",
        "\n",
        "def train_model(model, train_loader, test_loader, config, device):\n",
        "    \"\"\"\n",
        "    Main training function\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    history : dict\n",
        "        Training history with losses and metrics\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TRAINING CNN + GRU MODEL\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        weight_decay=config.WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5,\n",
        "        patience=config.LR_SCHEDULER_PATIENCE, verbose=True\n",
        "    )\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(patience=config.EARLY_STOPPING_PATIENCE)\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"\\nStarting training for {config.N_EPOCHS} epochs...\")\n",
        "    print(f\"Batch size: {config.BATCH_SIZE}, LR: {config.LEARNING_RATE}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for epoch in range(config.N_EPOCHS):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            model, train_loader, criterion, optimizer, device\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        val_loss, val_acc, val_f1, _, _ = evaluate(\n",
        "            model, test_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Store history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), os.path.join(config.MODEL_DIR, 'best_model.pt'))\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1:3d}/{config.N_EPOCHS} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
        "              f\"Val F1: {val_f1:.4f} | Time: {epoch_time:.1f}s\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if early_stopping(val_loss, model):\n",
        "            print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Training completed in {total_time/60:.1f} minutes\")\n",
        "    print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# Create model directory\n",
        "os.makedirs(config.MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Train the model\n",
        "history = train_model(model, train_loader, test_loader, config, device)\n",
        "\n",
        "# ## 8. Plot Training History\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training curves\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    # Loss plot\n",
        "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
        "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy plot\n",
        "    axes[1].plot(epochs, history['train_acc'], 'b-', label='Training Accuracy')\n",
        "    axes[1].plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 Score plot\n",
        "    axes[2].plot(epochs, history['val_f1'], 'g-', label='Validation F1')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('F1 Score')\n",
        "    axes[2].set_title('Validation F1 Score (Weighted)')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.MODEL_DIR, 'training_history.png'), dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nPlot saved to {config.MODEL_DIR}/training_history.png\")\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "# ## 9. Final Model Evaluation\n",
        "\n",
        "def final_evaluation(model, test_loader, device):\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"FINAL MODEL EVALUATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Load best model\n",
        "    best_model_path = os.path.join(config.MODEL_DIR, 'best_model.pt')\n",
        "    if os.path.exists(best_model_path):\n",
        "        model.load_state_dict(torch.load(best_model_path))\n",
        "        print(\"Loaded best model weights\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc, val_f1, all_preds, all_labels = evaluate(\n",
        "        model, test_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTest Set Results:\")\n",
        "    print(f\"  - Loss: {val_loss:.4f}\")\n",
        "    print(f\"  - Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
        "    print(f\"  - F1 Score (weighted): {val_f1:.4f}\")\n",
        "\n",
        "    # Additional metrics\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "    f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
        "    print(f\"  - F1 Score (macro): {f1_macro:.4f}\")\n",
        "    print(f\"  - F1 Score (micro): {f1_micro:.4f}\")\n",
        "\n",
        "    # Top-5 accuracy\n",
        "    # We need to get probabilities for this\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in test_loader:\n",
        "            batch_X = batch_X.to(device)\n",
        "            outputs = model(batch_X)\n",
        "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            all_probs.extend(probs)\n",
        "\n",
        "    all_probs = np.array(all_probs)\n",
        "    top5_preds = np.argsort(all_probs, axis=1)[:, -5:]\n",
        "    top5_correct = sum([1 for i, label in enumerate(all_labels) if label in top5_preds[i]])\n",
        "    top5_acc = top5_correct / len(all_labels)\n",
        "    print(f\"  - Top-5 Accuracy: {top5_acc:.4f} ({top5_acc*100:.2f}%)\")\n",
        "\n",
        "    return all_preds, all_labels, all_probs\n",
        "\n",
        "all_preds, all_labels, all_probs = final_evaluation(model, test_loader, device)\n",
        "\n",
        "# ## 10. Save Results\n",
        "\n",
        "def save_results(history, all_preds, all_labels, all_probs, config):\n",
        "    \"\"\"Save all results for the report notebook\"\"\"\n",
        "\n",
        "    results = {\n",
        "        'history': history,\n",
        "        'predictions': all_preds,\n",
        "        'true_labels': all_labels,\n",
        "        'probabilities': all_probs,\n",
        "        'n_classes': config.N_CLASSES,\n",
        "        'config': {\n",
        "            'n_channels': config.N_CHANNELS,\n",
        "            'n_samples': config.N_SAMPLES,\n",
        "            'n_classes': config.N_CLASSES,\n",
        "            'cnn_filters': config.CNN_FILTERS,\n",
        "            'gru_hidden': config.GRU_HIDDEN_SIZE,\n",
        "            'gru_layers': config.GRU_NUM_LAYERS,\n",
        "            'bidirectional': config.GRU_BIDIRECTIONAL,\n",
        "            'batch_size': config.BATCH_SIZE,\n",
        "            'learning_rate': config.LEARNING_RATE\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(config.MODEL_DIR, 'results.pkl'), 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "\n",
        "    print(f\"\\nResults saved to {config.MODEL_DIR}/results.pkl\")\n",
        "\n",
        "save_results(history, all_preds, all_labels, all_probs, config)\n",
        "\n",
        "# ## 11. Save Final Model\n",
        "\n",
        "def save_complete_model(model, config):\n",
        "    \"\"\"Save complete model with architecture\"\"\"\n",
        "\n",
        "    # Save full model (architecture + weights)\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'config': {\n",
        "            'n_channels': config.N_CHANNELS,\n",
        "            'n_samples': config.N_SAMPLES,\n",
        "            'n_classes': config.N_CLASSES,\n",
        "            'cnn_filters': config.CNN_FILTERS,\n",
        "            'cnn_kernel_size': config.CNN_KERNEL_SIZE,\n",
        "            'gru_hidden_size': config.GRU_HIDDEN_SIZE,\n",
        "            'gru_num_layers': config.GRU_NUM_LAYERS,\n",
        "            'gru_bidirectional': config.GRU_BIDIRECTIONAL,\n",
        "            'dense_hidden': config.DENSE_HIDDEN,\n",
        "            'dropout_cnn': config.DROPOUT_CNN,\n",
        "            'dropout_gru': config.DROPOUT_GRU,\n",
        "            'dropout_dense': config.DROPOUT_DENSE\n",
        "        }\n",
        "    }, os.path.join(config.MODEL_DIR, 'complete_model.pt'))\n",
        "\n",
        "    print(f\"Complete model saved to {config.MODEL_DIR}/complete_model.pt\")\n",
        "\n",
        "    # Print saved files\n",
        "    print(f\"\\nSaved files in {config.MODEL_DIR}:\")\n",
        "    for f in os.listdir(config.MODEL_DIR):\n",
        "        fpath = os.path.join(config.MODEL_DIR, f)\n",
        "        size = os.path.getsize(fpath) / (1024*1024)\n",
        "        print(f\"  - {f}: {size:.2f} MB\")\n",
        "\n",
        "save_complete_model(model, config)\n",
        "\n",
        "# ## 12. Summary\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"NOTEBOOK 2 COMPLETE - SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\"\"\n",
        "Model: CNN + GRU Hybrid for EEG Person Identification\n",
        "\n",
        "Architecture:\n",
        "- Input: ({config.N_CHANNELS} channels, {config.N_SAMPLES} samples)\n",
        "- CNN: 3 Conv1D blocks with filters {config.CNN_FILTERS}\n",
        "- GRU: {config.GRU_NUM_LAYERS} layers, {config.GRU_HIDDEN_SIZE} hidden units\n",
        "- Bidirectional: {config.GRU_BIDIRECTIONAL}\n",
        "- Output: {config.N_CLASSES} classes (subjects)\n",
        "\n",
        "Training:\n",
        "- Epochs trained: {len(history['train_loss'])}\n",
        "- Best validation accuracy: {max(history['val_acc']):.4f}\n",
        "- Final F1 score: {history['val_f1'][-1]:.4f}\n",
        "\n",
        "Saved Files:\n",
        "- {config.MODEL_DIR}/best_model.pt (best weights)\n",
        "- {config.MODEL_DIR}/complete_model.pt (full model)\n",
        "- {config.MODEL_DIR}/results.pkl (evaluation results)\n",
        "- {config.MODEL_DIR}/training_history.png (training plots)\n",
        "\n",
        "Next Step: Run Notebook 3 to generate the performance report\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "FDpWrQJrp21U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 1. Setup and Load Results\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    classification_report, confusion_matrix, top_k_accuracy_score\n",
        ")\n",
        "from collections import Counter\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Paths\n",
        "MODEL_DIR = '/content/models'\n",
        "REPORT_DIR = '/content/report'\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n",
        "\n",
        "def load_results():\n",
        "    \"\"\"Load saved results from model training\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"LOADING RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    with open(os.path.join(MODEL_DIR, 'results.pkl'), 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "\n",
        "    print(f\"Results loaded successfully!\")\n",
        "    print(f\"  - Number of test samples: {len(results['true_labels'])}\")\n",
        "    print(f\"  - Number of classes: {results['n_classes']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "results = load_results()\n",
        "\n",
        "# Extract data\n",
        "y_true = np.array(results['true_labels'])\n",
        "y_pred = np.array(results['predictions'])\n",
        "y_probs = np.array(results['probabilities'])\n",
        "history = results['history']\n",
        "model_config = results['config']\n",
        "\n",
        "# ## 2. Overall Performance Metrics\n",
        "\n",
        "def calculate_overall_metrics(y_true, y_pred, y_probs):\n",
        "    \"\"\"Calculate comprehensive metrics\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"OVERALL PERFORMANCE METRICS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # Basic metrics\n",
        "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "    metrics['f1_weighted'] = f1_score(y_true, y_pred, average='weighted')\n",
        "    metrics['f1_macro'] = f1_score(y_true, y_pred, average='macro')\n",
        "    metrics['f1_micro'] = f1_score(y_true, y_pred, average='micro')\n",
        "    metrics['precision_weighted'] = precision_score(y_true, y_pred, average='weighted')\n",
        "    metrics['recall_weighted'] = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Top-K accuracy\n",
        "    for k in [1, 3, 5, 10]:\n",
        "        metrics[f'top{k}_accuracy'] = top_k_accuracy_score(y_true, y_probs, k=k)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n┌─────────────────────────────────────────────────────────┐\")\n",
        "    print(\"│              CLASSIFICATION METRICS                      │\")\n",
        "    print(\"├─────────────────────────────────────────────────────────┤\")\n",
        "    print(f\"│  Accuracy (Top-1):          {metrics['accuracy']*100:>6.2f}%                     │\")\n",
        "    print(f\"│  Top-3 Accuracy:            {metrics['top3_accuracy']*100:>6.2f}%                     │\")\n",
        "    print(f\"│  Top-5 Accuracy:            {metrics['top5_accuracy']*100:>6.2f}%                     │\")\n",
        "    print(f\"│  Top-10 Accuracy:           {metrics['top10_accuracy']*100:>6.2f}%                     │\")\n",
        "    print(\"├─────────────────────────────────────────────────────────┤\")\n",
        "    print(f\"│  F1 Score (Weighted):       {metrics['f1_weighted']:.4f}                       │\")\n",
        "    print(f\"│  F1 Score (Macro):          {metrics['f1_macro']:.4f}                       │\")\n",
        "    print(f\"│  F1 Score (Micro):          {metrics['f1_micro']:.4f}                       │\")\n",
        "    print(\"├─────────────────────────────────────────────────────────┤\")\n",
        "    print(f\"│  Precision (Weighted):      {metrics['precision_weighted']:.4f}                       │\")\n",
        "    print(f\"│  Recall (Weighted):         {metrics['recall_weighted']:.4f}                       │\")\n",
        "    print(\"└─────────────────────────────────────────────────────────┘\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "metrics = calculate_overall_metrics(y_true, y_pred, y_probs)\n",
        "\n",
        "# ## 3. Confusion Matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, n_classes):\n",
        "    \"\"\"Generate and plot confusion matrix\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CONFUSION MATRIX\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Create figure with two versions: full and normalized\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "    # Raw confusion matrix (subset for visibility)\n",
        "    # For 109 classes, showing full matrix is impractical\n",
        "    # We'll show a subset and also the normalized version\n",
        "\n",
        "    # Plot 1: Full normalized confusion matrix as heatmap\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    cm_normalized = np.nan_to_num(cm_normalized)  # Handle division by zero\n",
        "\n",
        "    im1 = axes[0].imshow(cm_normalized, cmap='Blues', aspect='auto')\n",
        "    axes[0].set_title('Normalized Confusion Matrix (All 109 Subjects)', fontsize=12)\n",
        "    axes[0].set_xlabel('Predicted Subject', fontsize=10)\n",
        "    axes[0].set_ylabel('True Subject', fontsize=10)\n",
        "    plt.colorbar(im1, ax=axes[0], label='Proportion')\n",
        "\n",
        "    # Plot 2: Diagonal analysis - per-class accuracy\n",
        "    per_class_acc = np.diag(cm_normalized)\n",
        "\n",
        "    axes[1].bar(range(n_classes), per_class_acc, color='steelblue', alpha=0.7)\n",
        "    axes[1].axhline(y=np.mean(per_class_acc), color='red', linestyle='--',\n",
        "                    label=f'Mean: {np.mean(per_class_acc):.3f}')\n",
        "    axes[1].set_title('Per-Subject Classification Accuracy', fontsize=12)\n",
        "    axes[1].set_xlabel('Subject ID', fontsize=10)\n",
        "    axes[1].set_ylabel('Accuracy', fontsize=10)\n",
        "    axes[1].legend()\n",
        "    axes[1].set_xlim(-1, n_classes)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(REPORT_DIR, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"\\nPer-class accuracy statistics:\")\n",
        "    print(f\"  - Mean: {np.mean(per_class_acc):.4f}\")\n",
        "    print(f\"  - Std: {np.std(per_class_acc):.4f}\")\n",
        "    print(f\"  - Min: {np.min(per_class_acc):.4f} (Subject {np.argmin(per_class_acc)+1})\")\n",
        "    print(f\"  - Max: {np.max(per_class_acc):.4f} (Subject {np.argmax(per_class_acc)+1})\")\n",
        "\n",
        "    return cm, cm_normalized, per_class_acc\n",
        "\n",
        "cm, cm_normalized, per_class_acc = plot_confusion_matrix(y_true, y_pred, results['n_classes'])\n",
        "\n",
        "def plot_detailed_confusion_subset(y_true, y_pred, n_show=20):\n",
        "    \"\"\"Plot detailed confusion matrix for a subset of classes\"\"\"\n",
        "\n",
        "    # Select subjects with most samples for clearer visualization\n",
        "    label_counts = Counter(y_true)\n",
        "    top_subjects = [x[0] for x in label_counts.most_common(n_show)]\n",
        "    top_subjects.sort()\n",
        "\n",
        "    # Filter data for these subjects\n",
        "    mask = np.isin(y_true, top_subjects)\n",
        "    y_true_subset = y_true[mask]\n",
        "    y_pred_subset = y_pred[mask]\n",
        "\n",
        "    # Remap labels to 0-19 for visualization\n",
        "    label_map = {old: new for new, old in enumerate(top_subjects)}\n",
        "    y_true_remapped = np.array([label_map[y] for y in y_true_subset])\n",
        "    y_pred_remapped = np.array([label_map.get(y, -1) for y in y_pred_subset])\n",
        "\n",
        "    # Only keep predictions that fall within our subset\n",
        "    valid_mask = y_pred_remapped >= 0\n",
        "    y_true_remapped = y_true_remapped[valid_mask]\n",
        "    y_pred_remapped = y_pred_remapped[valid_mask]\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm_subset = confusion_matrix(y_true_remapped, y_pred_remapped,\n",
        "                                  labels=range(n_show))\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    sns.heatmap(cm_subset, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[f'S{s+1}' for s in top_subjects],\n",
        "                yticklabels=[f'S{s+1}' for s in top_subjects])\n",
        "    plt.title(f'Confusion Matrix (Top {n_show} Subjects by Sample Count)', fontsize=14)\n",
        "    plt.xlabel('Predicted Subject', fontsize=12)\n",
        "    plt.ylabel('True Subject', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(REPORT_DIR, 'confusion_matrix_subset.png'), dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nDetailed confusion matrix saved for {n_show} subjects\")\n",
        "\n",
        "plot_detailed_confusion_subset(y_true, y_pred, n_show=20)\n",
        "\n",
        "# ## 4. Per-Class F1 Score Analysis\n",
        "\n",
        "def analyze_per_class_f1(y_true, y_pred, n_classes):\n",
        "    \"\"\"Analyze F1 scores per class\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PER-CLASS F1 SCORE ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Calculate per-class metrics\n",
        "    f1_per_class = f1_score(y_true, y_pred, average=None, labels=range(n_classes))\n",
        "    precision_per_class = precision_score(y_true, y_pred, average=None,\n",
        "                                          labels=range(n_classes), zero_division=0)\n",
        "    recall_per_class = recall_score(y_true, y_pred, average=None,\n",
        "                                    labels=range(n_classes), zero_division=0)\n",
        "\n",
        "    # Plot F1 distribution\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # F1 Score distribution\n",
        "    axes[0, 0].hist(f1_per_class, bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].axvline(x=np.mean(f1_per_class), color='red', linestyle='--',\n",
        "                       label=f'Mean: {np.mean(f1_per_class):.3f}')\n",
        "    axes[0, 0].set_title('F1 Score Distribution Across Subjects')\n",
        "    axes[0, 0].set_xlabel('F1 Score')\n",
        "    axes[0, 0].set_ylabel('Number of Subjects')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    # Precision vs Recall scatter\n",
        "    axes[0, 1].scatter(precision_per_class, recall_per_class, alpha=0.6, c='steelblue')\n",
        "    axes[0, 1].plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
        "    axes[0, 1].set_title('Precision vs Recall per Subject')\n",
        "    axes[0, 1].set_xlabel('Precision')\n",
        "    axes[0, 1].set_ylabel('Recall')\n",
        "    axes[0, 1].set_xlim(-0.05, 1.05)\n",
        "    axes[0, 1].set_ylim(-0.05, 1.05)\n",
        "\n",
        "    # Sorted F1 scores\n",
        "    sorted_indices = np.argsort(f1_per_class)\n",
        "    axes[1, 0].bar(range(n_classes), f1_per_class[sorted_indices],\n",
        "                   color='steelblue', alpha=0.7)\n",
        "    axes[1, 0].axhline(y=np.mean(f1_per_class), color='red', linestyle='--')\n",
        "    axes[1, 0].set_title('F1 Scores Sorted (Ascending)')\n",
        "    axes[1, 0].set_xlabel('Subject Rank')\n",
        "    axes[1, 0].set_ylabel('F1 Score')\n",
        "\n",
        "    # Best and worst performers\n",
        "    n_show = 15\n",
        "    best_idx = sorted_indices[-n_show:][::-1]\n",
        "    worst_idx = sorted_indices[:n_show]\n",
        "\n",
        "    x_labels = [f'S{i+1}' for i in worst_idx] + ['...'] + [f'S{i+1}' for i in best_idx]\n",
        "    x_values = list(f1_per_class[worst_idx]) + [np.nan] + list(f1_per_class[best_idx])\n",
        "    colors = ['red']*n_show + ['white'] + ['green']*n_show\n",
        "\n",
        "    axes[1, 1].bar(range(len(x_labels)), x_values, color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[1, 1].set_xticks(range(len(x_labels)))\n",
        "    axes[1, 1].set_xticklabels(x_labels, rotation=45, ha='right')\n",
        "    axes[1, 1].set_title(f'Best and Worst {n_show} Subjects by F1 Score')\n",
        "    axes[1, 1].set_ylabel('F1 Score')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(REPORT_DIR, 'f1_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"\\nF1 Score Statistics:\")\n",
        "    print(f\"  - Mean: {np.mean(f1_per_class):.4f}\")\n",
        "    print(f\"  - Std: {np.std(f1_per_class):.4f}\")\n",
        "    print(f\"  - Min: {np.min(f1_per_class):.4f}\")\n",
        "    print(f\"  - Max: {np.max(f1_per_class):.4f}\")\n",
        "\n",
        "    print(f\"\\nTop 5 Best Performing Subjects:\")\n",
        "    for i, idx in enumerate(sorted_indices[-5:][::-1]):\n",
        "        print(f\"  {i+1}. Subject {idx+1}: F1={f1_per_class[idx]:.4f}\")\n",
        "\n",
        "    print(f\"\\nTop 5 Worst Performing Subjects:\")\n",
        "    for i, idx in enumerate(sorted_indices[:5]):\n",
        "        print(f\"  {i+1}. Subject {idx+1}: F1={f1_per_class[idx]:.4f}\")\n",
        "\n",
        "    return f1_per_class, precision_per_class, recall_per_class\n",
        "\n",
        "f1_per_class, precision_per_class, recall_per_class = analyze_per_class_f1(\n",
        "    y_true, y_pred, results['n_classes']\n",
        ")\n",
        "\n",
        "# ## 5. Training History Analysis\n",
        "\n",
        "def plot_training_analysis(history):\n",
        "    \"\"\"Detailed analysis of training history\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TRAINING ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    # Loss curves\n",
        "    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Training', linewidth=2)\n",
        "    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
        "    axes[0, 0].set_title('Loss Curves', fontsize=12)\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy curves\n",
        "    axes[0, 1].plot(epochs, history['train_acc'], 'b-', label='Training', linewidth=2)\n",
        "    axes[0, 1].plot(epochs, history['val_acc'], 'r-', label='Validation', linewidth=2)\n",
        "    axes[0, 1].set_title('Accuracy Curves', fontsize=12)\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Gap between train and val (overfitting indicator)\n",
        "    train_val_gap = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
        "    axes[1, 0].plot(epochs, train_val_gap, 'purple', linewidth=2)\n",
        "    axes[1, 0].axhline(y=0, color='gray', linestyle='--')\n",
        "    axes[1, 0].fill_between(epochs, 0, train_val_gap, alpha=0.3, color='purple')\n",
        "    axes[1, 0].set_title('Train-Validation Accuracy Gap (Overfitting Indicator)', fontsize=12)\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Gap (Train - Val)')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 score progression\n",
        "    axes[1, 1].plot(epochs, history['val_f1'], 'g-', linewidth=2)\n",
        "    axes[1, 1].set_title('Validation F1 Score Progression', fontsize=12)\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('F1 Score (Weighted)')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(REPORT_DIR, 'training_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print training statistics\n",
        "    print(f\"\\nTraining Statistics:\")\n",
        "    print(f\"  - Total epochs: {len(history['train_loss'])}\")\n",
        "    print(f\"  - Best validation accuracy: {max(history['val_acc']):.4f} \"\n",
        "          f\"(Epoch {np.argmax(history['val_acc'])+1})\")\n",
        "    print(f\"  - Best validation F1: {max(history['val_f1']):.4f}\")\n",
        "    print(f\"  - Final train-val gap: {train_val_gap[-1]:.4f}\")\n",
        "\n",
        "    # Convergence analysis\n",
        "    final_10_val_loss = history['val_loss'][-10:]\n",
        "    convergence_std = np.std(final_10_val_loss)\n",
        "    print(f\"  - Convergence (last 10 epochs loss std): {convergence_std:.6f}\")\n",
        "\n",
        "plot_training_analysis(history)\n",
        "\n",
        "# ## 6. Error Analysis\n",
        "\n",
        "def analyze_errors(y_true, y_pred, y_probs, n_classes):\n",
        "    \"\"\"Analyze model errors\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ERROR ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Find misclassified samples\n",
        "    errors = y_true != y_pred\n",
        "    error_indices = np.where(errors)[0]\n",
        "\n",
        "    print(f\"\\nError Statistics:\")\n",
        "    print(f\"  - Total test samples: {len(y_true)}\")\n",
        "    print(f\"  - Correct predictions: {np.sum(~errors)}\")\n",
        "    print(f\"  - Incorrect predictions: {np.sum(errors)}\")\n",
        "    print(f\"  - Error rate: {np.mean(errors)*100:.2f}%\")\n",
        "\n",
        "    # Analyze confidence of errors\n",
        "    correct_conf = y_probs[~errors].max(axis=1)\n",
        "    error_conf = y_probs[errors].max(axis=1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Confidence distribution\n",
        "    axes[0].hist(correct_conf, bins=30, alpha=0.6, label='Correct', color='green', density=True)\n",
        "    axes[0].hist(error_conf, bins=30, alpha=0.6, label='Incorrect', color='red', density=True)\n",
        "    axes[0].set_title('Prediction Confidence Distribution')\n",
        "    axes[0].set_xlabel('Max Probability (Confidence)')\n",
        "    axes[0].set_ylabel('Density')\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Most common confusion pairs\n",
        "    confusion_pairs = []\n",
        "    for i in error_indices:\n",
        "        confusion_pairs.append((y_true[i], y_pred[i]))\n",
        "\n",
        "    pair_counts = Counter(confusion_pairs)\n",
        "    top_confusions = pair_counts.most_common(15)\n",
        "\n",
        "    if top_confusions:\n",
        "        labels = [f'S{t+1}→S{p+1}' for (t, p), _ in top_confusions]\n",
        "        counts = [c for _, c in top_confusions]\n",
        "\n",
        "        axes[1].barh(range(len(labels)), counts, color='coral')\n",
        "        axes[1].set_yticks(range(len(labels)))\n",
        "        axes[1].set_yticklabels(labels)\n",
        "        axes[1].set_xlabel('Count')\n",
        "        axes[1].set_title('Most Common Confusion Pairs')\n",
        "        axes[1].invert_yaxis()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(REPORT_DIR, 'error_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nConfidence Analysis:\")\n",
        "    print(f\"  - Mean confidence (correct): {np.mean(correct_conf):.4f}\")\n",
        "    print(f\"  - Mean confidence (incorrect): {np.mean(error_conf):.4f}\")\n",
        "\n",
        "    if top_confusions:\n",
        "        print(f\"\\nTop 5 Most Confused Subject Pairs:\")\n",
        "        for i, ((true_label, pred_label), count) in enumerate(top_confusions[:5]):\n",
        "            print(f\"  {i+1}. Subject {true_label+1} → Subject {pred_label+1}: {count} times\")\n",
        "\n",
        "analyze_errors(y_true, y_pred, y_probs, results['n_classes'])"
      ],
      "metadata": {
        "id": "5i5tTJLGp4p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EEG Spectrograms and t-SNE Feature Embeddings\n",
        "# =============================================================================\n",
        "\n",
        "# ## 1. Setup\n",
        "\n",
        "\n",
        "!pip install torch torchvision -q\n",
        "!pip install scikit-learn -q\n",
        "!pip install scipy -q\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Paths\n",
        "PROCESSED_DIR = '/content/processed_data'\n",
        "MODEL_DIR = '/content/models'\n",
        "VIZ_DIR = '/content/visualizations'\n",
        "os.makedirs(VIZ_DIR, exist_ok=True)\n",
        "REPORT_DIR = '/content/report'\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)\n",
        "# ## 2. Load Data and Model\n",
        "\n",
        "# Load preprocessed data\n",
        "X_test = np.load(os.path.join(PROCESSED_DIR, 'X_test.npy'))\n",
        "y_test = np.load(os.path.join(PROCESSED_DIR, 'y_test.npy'))\n",
        "\n",
        "with open(os.path.join(PROCESSED_DIR, 'metadata.pkl'), 'rb') as f:\n",
        "    metadata = pickle.load(f)\n",
        "\n",
        "print(f\"Test data shape: {X_test.shape}\")\n",
        "print(f\"Number of subjects: {len(np.unique(y_test))}\")\n",
        "\n",
        "# Configuration\n",
        "SAMPLING_RATE = metadata['sampling_rate']  # 160 Hz\n",
        "MOTOR_CHANNELS = metadata['motor_channels']\n",
        "N_CHANNELS = X_test.shape[1]\n",
        "N_SAMPLES = X_test.shape[2]\n",
        "\n",
        "# Load the trained model\n",
        "class CNN_GRU_Model(nn.Module):\n",
        "    \"\"\"Recreate model architecture for loading weights\"\"\"\n",
        "\n",
        "    def __init__(self, n_channels, n_samples, n_classes,\n",
        "                 cnn_filters=[32, 64, 128], kernel_size=7,\n",
        "                 gru_hidden=128, gru_layers=2, bidirectional=True):\n",
        "        super(CNN_GRU_Model, self).__init__()\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            nn.Conv1d(n_channels, cnn_filters[0], kernel_size=kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(cnn_filters[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(cnn_filters[0], cnn_filters[1], kernel_size=kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(cnn_filters[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(cnn_filters[1], cnn_filters[2], kernel_size=kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(cnn_filters[2]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=cnn_filters[2],\n",
        "            hidden_size=gru_hidden,\n",
        "            num_layers=gru_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=0.3 if gru_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        gru_output_size = gru_hidden * (2 if bidirectional else 1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(gru_output_size, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, n_classes)\n",
        "        )\n",
        "\n",
        "        self.gru_hidden = gru_hidden\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        cnn_out = self.cnn_layers(x)\n",
        "        gru_in = cnn_out.transpose(1, 2)\n",
        "        gru_out, hidden = self.gru(gru_in)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            final_hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            final_hidden = hidden[-1]\n",
        "\n",
        "        output = self.classifier(final_hidden)\n",
        "        return output\n",
        "\n",
        "    def get_features(self, x):\n",
        "        \"\"\"Extract features before classification layer\"\"\"\n",
        "        cnn_out = self.cnn_layers(x)\n",
        "        gru_in = cnn_out.transpose(1, 2)\n",
        "        gru_out, hidden = self.gru(gru_in)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            final_hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            final_hidden = hidden[-1]\n",
        "\n",
        "        return final_hidden\n",
        "\n",
        "    def get_cnn_features(self, x):\n",
        "        \"\"\"Extract CNN features only\"\"\"\n",
        "        return self.cnn_layers(x)\n",
        "\n",
        "# Load model\n",
        "checkpoint = torch.load(os.path.join(MODEL_DIR, 'complete_model.pt'), map_location=device)\n",
        "model_config = checkpoint['config']\n",
        "\n",
        "model = CNN_GRU_Model(\n",
        "    n_channels=model_config['n_channels'],\n",
        "    n_samples=model_config['n_samples'],\n",
        "    n_classes=model_config['n_classes'],\n",
        "    cnn_filters=model_config['cnn_filters'],\n",
        "    gru_hidden=model_config['gru_hidden_size'],\n",
        "    gru_layers=model_config['gru_num_layers'],\n",
        "    bidirectional=model_config['gru_bidirectional']\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# ## 3. EEG Signal Visualization\n",
        "\n",
        "def plot_eeg_signals(X, y, subject_ids=[0, 1, 2], channel_names=None):\n",
        "    \"\"\"\n",
        "    Plot raw EEG signals for different subjects\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"EEG SIGNAL VISUALIZATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    n_subjects = len(subject_ids)\n",
        "    fig, axes = plt.subplots(n_subjects, 1, figsize=(14, 3*n_subjects))\n",
        "\n",
        "    if n_subjects == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    time = np.arange(N_SAMPLES) / SAMPLING_RATE\n",
        "\n",
        "    for idx, subject_id in enumerate(subject_ids):\n",
        "        # Find a sample from this subject\n",
        "        sample_indices = np.where(y == subject_id)[0]\n",
        "        if len(sample_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        sample_idx = sample_indices[0]\n",
        "        eeg_data = X[sample_idx]\n",
        "\n",
        "        # Plot each channel with offset\n",
        "        for ch in range(min(N_CHANNELS, 10)):  # Plot max 10 channels\n",
        "            offset = ch * 3  # Vertical offset\n",
        "            axes[idx].plot(time, eeg_data[ch] + offset, linewidth=0.8,\n",
        "                          label=MOTOR_CHANNELS[ch] if channel_names else f'Ch{ch}')\n",
        "\n",
        "        axes[idx].set_title(f'Subject {subject_id + 1} - EEG Segment', fontsize=12)\n",
        "        axes[idx].set_xlabel('Time (s)')\n",
        "        axes[idx].set_ylabel('Amplitude (normalized)')\n",
        "        axes[idx].set_xlim([0, time[-1]])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIZ_DIR, 'eeg_signals.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Plot saved to {VIZ_DIR}/eeg_signals.png\")\n",
        "\n",
        "# Plot EEG signals for 3 different subjects\n",
        "plot_eeg_signals(X_test, y_test, subject_ids=[0, 50, 100], channel_names=MOTOR_CHANNELS)\n",
        "\n",
        "# ## 4. Spectrogram Visualization\n",
        "\n",
        "def compute_spectrogram(signal_data, fs, nperseg=64, noverlap=48):\n",
        "    \"\"\"\n",
        "    Compute spectrogram using Short-Time Fourier Transform\n",
        "    \"\"\"\n",
        "    f, t, Sxx = signal.spectrogram(signal_data, fs=fs,\n",
        "                                    nperseg=nperseg, noverlap=noverlap)\n",
        "    return f, t, Sxx\n",
        "\n",
        "def plot_spectrograms(X, y, subject_ids=[0, 1, 2], channel_idx=5):\n",
        "    \"\"\"\n",
        "    Plot spectrograms for EEG segments from different subjects\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"SPECTROGRAM VISUALIZATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    n_subjects = len(subject_ids)\n",
        "    fig, axes = plt.subplots(n_subjects, 2, figsize=(14, 4*n_subjects))\n",
        "\n",
        "    if n_subjects == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for idx, subject_id in enumerate(subject_ids):\n",
        "        # Find a sample from this subject\n",
        "        sample_indices = np.where(y == subject_id)[0]\n",
        "        if len(sample_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        sample_idx = sample_indices[0]\n",
        "        eeg_segment = X[sample_idx, channel_idx, :]\n",
        "\n",
        "        # Compute spectrogram\n",
        "        f, t, Sxx = compute_spectrogram(eeg_segment, SAMPLING_RATE)\n",
        "\n",
        "        # Plot raw signal\n",
        "        time = np.arange(len(eeg_segment)) / SAMPLING_RATE\n",
        "        axes[idx, 0].plot(time, eeg_segment, 'b-', linewidth=1)\n",
        "        axes[idx, 0].set_title(f'Subject {subject_id+1} - Raw EEG (Channel: {MOTOR_CHANNELS[channel_idx]})')\n",
        "        axes[idx, 0].set_xlabel('Time (s)')\n",
        "        axes[idx, 0].set_ylabel('Amplitude')\n",
        "\n",
        "        # Plot spectrogram\n",
        "        im = axes[idx, 1].pcolormesh(t, f, 10 * np.log10(Sxx + 1e-10),\n",
        "                                      shading='gouraud', cmap='viridis')\n",
        "        axes[idx, 1].set_title(f'Subject {subject_id+1} - Spectrogram')\n",
        "        axes[idx, 1].set_xlabel('Time (s)')\n",
        "        axes[idx, 1].set_ylabel('Frequency (Hz)')\n",
        "        axes[idx, 1].set_ylim([0, 50])  # Focus on relevant frequencies\n",
        "        plt.colorbar(im, ax=axes[idx, 1], label='Power (dB)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIZ_DIR, 'spectrograms.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Plot saved to {VIZ_DIR}/spectrograms.png\")\n",
        "\n",
        "plot_spectrograms(X_test, y_test, subject_ids=[0, 50, 100], channel_idx=5)\n",
        "\n",
        "def plot_average_spectrograms(X, y, n_subjects_show=6):\n",
        "    \"\"\"\n",
        "    Plot average spectrograms per subject to show subject-specific patterns\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"AVERAGE SPECTROGRAMS PER SUBJECT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Select subjects with enough samples\n",
        "    unique_subjects = np.unique(y)\n",
        "    np.random.seed(42)\n",
        "    selected_subjects = np.random.choice(unique_subjects,\n",
        "                                          size=min(n_subjects_show, len(unique_subjects)),\n",
        "                                          replace=False)\n",
        "    selected_subjects.sort()\n",
        "\n",
        "    n_cols = 3\n",
        "    n_rows = (len(selected_subjects) + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, subject_id in enumerate(selected_subjects):\n",
        "        # Get all samples for this subject\n",
        "        subject_mask = y == subject_id\n",
        "        subject_data = X[subject_mask]\n",
        "\n",
        "        # Average spectrogram across all segments and channels\n",
        "        avg_spectrogram = np.zeros((33, 9))  # Will accumulate\n",
        "        count = 0\n",
        "\n",
        "        for segment in subject_data[:20]:  # Use max 20 segments\n",
        "            for ch in range(min(5, N_CHANNELS)):  # Average over channels\n",
        "                f, t, Sxx = compute_spectrogram(segment[ch], SAMPLING_RATE)\n",
        "                if Sxx.shape == avg_spectrogram.shape:\n",
        "                    avg_spectrogram += Sxx\n",
        "                    count += 1\n",
        "\n",
        "        if count > 0:\n",
        "            avg_spectrogram /= count\n",
        "\n",
        "        # Plot\n",
        "        im = axes[idx].pcolormesh(t, f, 10 * np.log10(avg_spectrogram + 1e-10),\n",
        "                                   shading='gouraud', cmap='magma')\n",
        "        axes[idx].set_title(f'Subject {subject_id + 1}', fontsize=11)\n",
        "        axes[idx].set_xlabel('Time (s)', fontsize=9)\n",
        "        axes[idx].set_ylabel('Frequency (Hz)', fontsize=9)\n",
        "        axes[idx].set_ylim([0, 45])\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for idx in range(len(selected_subjects), len(axes)):\n",
        "        axes[idx].set_visible(False)\n",
        "\n",
        "    plt.suptitle('Average Spectrograms by Subject (Motor Cortex Channels)', fontsize=14, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIZ_DIR, 'avg_spectrograms.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Plot saved to {VIZ_DIR}/avg_spectrograms.png\")\n",
        "\n",
        "plot_average_spectrograms(X_test, y_test, n_subjects_show=9)\n",
        "\n",
        "# ## 5. t-SNE Feature Embedding Visualization\n",
        "\n",
        "def extract_features(model, X, batch_size=64):\n",
        "    \"\"\"\n",
        "    Extract deep features from the trained model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    features = []\n",
        "\n",
        "    n_samples = len(X)\n",
        "    n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(n_batches), desc=\"Extracting features\"):\n",
        "            start_idx = i * batch_size\n",
        "            end_idx = min((i + 1) * batch_size, n_samples)\n",
        "\n",
        "            batch = torch.FloatTensor(X[start_idx:end_idx]).to(device)\n",
        "            batch_features = model.get_features(batch)\n",
        "            features.append(batch_features.cpu().numpy())\n",
        "\n",
        "    return np.concatenate(features, axis=0)\n",
        "\n",
        "# Extract features\n",
        "print(\"=\" * 60)\n",
        "print(\"EXTRACTING DEEP FEATURES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Use a subset for faster computation\n",
        "max_samples = 5000\n",
        "if len(X_test) > max_samples:\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.choice(len(X_test), max_samples, replace=False)\n",
        "    X_subset = X_test[indices]\n",
        "    y_subset = y_test[indices]\n",
        "else:\n",
        "    X_subset = X_test\n",
        "    y_subset = y_test\n",
        "\n",
        "features = extract_features(model, X_subset)\n",
        "print(f\"Feature shape: {features.shape}\")\n",
        "\n",
        "def plot_tsne(features, labels, n_components=2, perplexity=30, n_iter=1000):\n",
        "    \"\"\"\n",
        "    Visualize features using t-SNE\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"t-SNE VISUALIZATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(f\"Running t-SNE on {len(features)} samples...\")\n",
        "    print(f\"Parameters: perplexity={perplexity}, n_iter={n_iter}\")\n",
        "\n",
        "    # First reduce with PCA if features are high-dimensional\n",
        "    if features.shape[1] > 50:\n",
        "        print(\"Applying PCA reduction first...\")\n",
        "        pca = PCA(n_components=50)\n",
        "        features_pca = pca.fit_transform(features)\n",
        "        print(f\"PCA variance explained: {sum(pca.explained_variance_ratio_)*100:.1f}%\")\n",
        "    else:\n",
        "        features_pca = features\n",
        "\n",
        "    # Apply t-SNE\n",
        "    tsne = TSNE(n_components=n_components, perplexity=perplexity,\n",
        "                n_iter=n_iter, random_state=42, verbose=1)\n",
        "    features_tsne = tsne.fit_transform(features_pca)\n",
        "\n",
        "    print(f\"t-SNE complete! Output shape: {features_tsne.shape}\")\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "    # Plot 1: All subjects colored\n",
        "    n_subjects = len(np.unique(labels))\n",
        "    colors = plt.cm.nipy_spectral(np.linspace(0, 1, n_subjects))\n",
        "\n",
        "    for subject_id in np.unique(labels):\n",
        "        mask = labels == subject_id\n",
        "        axes[0].scatter(features_tsne[mask, 0], features_tsne[mask, 1],\n",
        "                       c=[colors[subject_id]], alpha=0.5, s=10, label=f'S{subject_id+1}')\n",
        "\n",
        "    axes[0].set_title('t-SNE: All Subjects', fontsize=12)\n",
        "    axes[0].set_xlabel('t-SNE Dimension 1')\n",
        "    axes[0].set_ylabel('t-SNE Dimension 2')\n",
        "\n",
        "    # Plot 2: Highlight specific subjects\n",
        "    highlight_subjects = [0, 25, 50, 75, 100]\n",
        "    highlight_subjects = [s for s in highlight_subjects if s in np.unique(labels)]\n",
        "\n",
        "    # Plot all in gray\n",
        "    axes[1].scatter(features_tsne[:, 0], features_tsne[:, 1],\n",
        "                   c='lightgray', alpha=0.3, s=10, label='Other')\n",
        "\n",
        "    # Highlight selected subjects\n",
        "    highlight_colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
        "    for i, subject_id in enumerate(highlight_subjects):\n",
        "        mask = labels == subject_id\n",
        "        axes[1].scatter(features_tsne[mask, 0], features_tsne[mask, 1],\n",
        "                       c=highlight_colors[i], alpha=0.8, s=30,\n",
        "                       label=f'Subject {subject_id+1}')\n",
        "\n",
        "    axes[1].set_title('t-SNE: Highlighted Subjects', fontsize=12)\n",
        "    axes[1].set_xlabel('t-SNE Dimension 1')\n",
        "    axes[1].set_ylabel('t-SNE Dimension 2')\n",
        "    axes[1].legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIZ_DIR, 'tsne_embeddings.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Plot saved to {VIZ_DIR}/tsne_embeddings.png\")\n",
        "\n",
        "    return features_tsne\n",
        "\n",
        "features_tsne = plot_tsne(features, y_subset, perplexity=30, n_iter=1000)\n",
        "\n",
        "def plot_tsne_quality_analysis(features_tsne, labels):\n",
        "    \"\"\"\n",
        "    Analyze the quality of t-SNE clustering\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"t-SNE CLUSTER QUALITY ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Calculate cluster centroids\n",
        "    unique_labels = np.unique(labels)\n",
        "    centroids = []\n",
        "    spreads = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        mask = labels == label\n",
        "        points = features_tsne[mask]\n",
        "        centroid = np.mean(points, axis=0)\n",
        "        spread = np.mean(np.linalg.norm(points - centroid, axis=1))\n",
        "        centroids.append(centroid)\n",
        "        spreads.append(spread)\n",
        "\n",
        "    centroids = np.array(centroids)\n",
        "    spreads = np.array(spreads)\n",
        "\n",
        "    # Plot 1: Cluster spread distribution\n",
        "    axes[0].hist(spreads, bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0].axvline(np.mean(spreads), color='red', linestyle='--',\n",
        "                    label=f'Mean: {np.mean(spreads):.2f}')\n",
        "    axes[0].set_title('Distribution of Cluster Spreads')\n",
        "    axes[0].set_xlabel('Cluster Spread (distance from centroid)')\n",
        "    axes[0].set_ylabel('Number of Subjects')\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Plot 2: Cluster separation analysis\n",
        "    # Calculate inter-cluster distances\n",
        "    from scipy.spatial.distance import pdist\n",
        "    inter_cluster_dist = pdist(centroids)\n",
        "\n",
        "    axes[1].hist(inter_cluster_dist, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "    axes[1].axvline(np.mean(inter_cluster_dist), color='red', linestyle='--',\n",
        "                    label=f'Mean: {np.mean(inter_cluster_dist):.2f}')\n",
        "    axes[1].set_title('Distribution of Inter-Cluster Distances')\n",
        "    axes[1].set_xlabel('Distance Between Cluster Centroids')\n",
        "    axes[1].set_ylabel('Count')\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIZ_DIR, 'tsne_quality.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"\\nCluster Quality Metrics:\")\n",
        "    print(f\"  - Mean intra-cluster spread: {np.mean(spreads):.4f}\")\n",
        "    print(f\"  - Mean inter-cluster distance: {np.mean(inter_cluster_dist):.4f}\")\n",
        "    print(f\"  - Separation ratio: {np.mean(inter_cluster_dist)/np.mean(spreads):.4f}\")\n",
        "    print(f\"    (Higher is better - indicates well-separated clusters)\")\n",
        "\n",
        "plot_tsne_quality_analysis(features_tsne, y_subset)\n",
        "\n",
        "# ## 6. CNN Feature Maps Visualization\n",
        "\n",
        "def visualize_cnn_features(model, X, sample_indices=[0, 1, 2]):\n",
        "    \"\"\"\n",
        "    Visualize intermediate CNN feature maps\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CNN FEATURE MAPS VISUALIZATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Get activations from each CNN layer\n",
        "    def get_activation(name, activations):\n",
        "        def hook(model, input, output):\n",
        "            activations[name] = output.detach().cpu().numpy()\n",
        "        return hook\n",
        "\n",
        "    # Register hooks for each layer\n",
        "    activations = {}\n",
        "    hooks = []\n",
        "\n",
        "    for i, layer in enumerate(model.cnn_layers):\n",
        "        if isinstance(layer, nn.Conv1d):\n",
        "            hook = layer.register_forward_hook(get_activation(f'conv_{i}', activations))\n",
        "            hooks.append(hook)\n",
        "\n",
        "    # Process samples\n",
        "    for sample_idx in sample_indices:\n",
        "        subject_id = y_subset[sample_idx]\n",
        "        sample = torch.FloatTensor(X[sample_idx:sample_idx+1]).to(device)\n",
        "\n",
        "        # Forward pass to get activations\n",
        "        with torch.no_grad():\n",
        "            _ = model(sample)\n",
        "\n",
        "        # Plot\n",
        "        n_layers = len(activations)\n",
        "        fig, axes = plt.subplots(1, n_layers + 1, figsize=(16, 4))\n",
        "\n",
        "        # Original input\n",
        "        time = np.arange(X.shape[2]) / SAMPLING_RATE\n",
        "        for ch in range(min(5, X.shape[1])):\n",
        "            axes[0].plot(time, X[sample_idx, ch] + ch*2, linewidth=0.8)\n",
        "        axes[0].set_title(f'Input (Subject {subject_id+1})')\n",
        "        axes[0].set_xlabel('Time (s)')\n",
        "\n",
        "        # Feature maps\n",
        "        for idx, (name, activation) in enumerate(activations.items()):\n",
        "            act = activation[0]  # First sample in batch\n",
        "            # Show subset of filters\n",
        "            n_filters_show = min(16, act.shape[0])\n",
        "            im = axes[idx+1].imshow(act[:n_filters_show], aspect='auto', cmap='viridis')\n",
        "            axes[idx+1].set_title(f'{name} Features')\n",
        "            axes[idx+1].set_xlabel('Time Steps')\n",
        "            axes[idx+1].set_ylabel('Filter')\n",
        "\n",
        "        plt.suptitle(f'CNN Feature Maps - Subject {subject_id+1}', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(VIZ_DIR, f'cnn_features_sample_{sample_idx}.png'),\n",
        "                   dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    # Remove hooks\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    print(f\"Feature maps saved to {VIZ_DIR}/\")\n",
        "\n",
        "visualize_cnn_features(model, X_subset, sample_indices=[0, 50, 100])\n",
        "\n",
        "# ## 7. Power Spectrum Analysis\n",
        "\n",
        "def plot_power_spectrum_by_subject(X, y, subject_ids=[0, 50, 100]):\n",
        "    \"\"\"\n",
        "    Plot average power spectrum for different subjects\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"POWER SPECTRUM ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
        "\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(subject_ids)))\n",
        "\n",
        "    for idx, subject_id in enumerate(subject_ids):\n",
        "        # Get all samples for this subject\n",
        "        subject_mask = y == subject_id\n",
        "        subject_data = X[subject_mask]\n",
        "\n",
        "        # Calculate average power spectrum\n",
        "        all_psd = []\n",
        "        for segment in subject_data[:50]:  # Use max 50 segments\n",
        "            for ch in range(min(5, N_CHANNELS)):\n",
        "                freqs, psd = signal.welch(segment[ch], fs=SAMPLING_RATE, nperseg=128)\n",
        "                all_psd.append(psd)\n",
        "\n",
        "        avg_psd = np.mean(all_psd, axis=0)\n",
        "\n",
        "        ax.semilogy(freqs, avg_psd, color=colors[idx], linewidth=2,\n",
        "                   label=f'Subject {subject_id+1}')\n",
        "\n",
        "    ax.set_xlabel('Frequency (Hz)', fontsize=12)\n",
        "    ax.set_ylabel('Power Spectral Density', fontsize=12)\n",
        "    ax.set_title('Average Power Spectrum by Subject', fontsize=14)\n",
        "    ax.set_xlim([0, 50])\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Mark EEG frequency bands\n",
        "    bands = {'Delta': (0.5, 4), 'Theta': (4, 8), 'Alpha': (8, 13),\n",
        "             'Beta': (13, 30), 'Gamma': (30, 50)}\n",
        "\n",
        "    for band_name, (low, high) in bands.items():\n",
        "        ax.axvspan(low, high, alpha=0.1)\n",
        "        ax.text((low + high) / 2, ax.get_ylim()[1] * 0.5, band_name,\n",
        "               ha='center', fontsize=9, rotation=90, alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIZ_DIR, 'power_spectrum.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Plot saved to {VIZ_DIR}/power_spectrum.png\")\n",
        "\n",
        "plot_power_spectrum_by_subject(X_subset, y_subset, subject_ids=[0, 25, 50, 75, 100])\n",
        "\n",
        "# ## 8. Summary\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"NOTEBOOK 4 COMPLETE - VISUALIZATIONS GENERATED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\"\"\n",
        "Generated Visualizations:\n",
        "\n",
        "1. EEG Signals\n",
        "   - {VIZ_DIR}/eeg_signals.png\n",
        "\n",
        "2. Spectrograms\n",
        "   - {VIZ_DIR}/spectrograms.png\n",
        "   - {VIZ_DIR}/avg_spectrograms.png\n",
        "\n",
        "3. t-SNE Feature Embeddings\n",
        "   - {VIZ_DIR}/tsne_embeddings.png\n",
        "   - {VIZ_DIR}/tsne_quality.png\n",
        "\n",
        "4. CNN Feature Maps\n",
        "   - {VIZ_DIR}/cnn_features_sample_*.png\n",
        "\n",
        "5. Power Spectrum Analysis\n",
        "   - {VIZ_DIR}/power_spectrum.png\n",
        "\n",
        "All files saved in: {VIZ_DIR}\n",
        "\"\"\")\n",
        "\n",
        "# List all generated files\n",
        "print(\"\\nGenerated files:\")\n",
        "for filename in sorted(os.listdir(VIZ_DIR)):\n",
        "    filepath = os.path.join(VIZ_DIR, filename)\n",
        "    size_kb = os.path.getsize(filepath) / 1024\n",
        "    print(f\"  - {filename}: {size_kb:.1f} KB\")"
      ],
      "metadata": {
        "id": "qdFRyQirqG7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}